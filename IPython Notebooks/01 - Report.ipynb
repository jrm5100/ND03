{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Street Maps Data Import and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for Raleigh, North Carolina was downloaded from MapZen (https://mapzen.com/data/metro-extracts).\n",
    "\n",
    "It was converted to JSON while being structured and corrected/normalized, then imported into mongodb.  Code for this processing is detailed in \"02 - Code used for Data Wrangling and Exploration\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "db = client.osm\n",
    "collection = db.raleigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems encountered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are certainly multiple problems or areas for improvement, but three issues that stuck out were:\n",
    "\n",
    "1. Inconsistent Street Names\n",
    "2. Questionable Validity of Education Ammenity Tags\n",
    "3. Non-standardized Postal Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Street Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from the expected standardization (such as \"st\" to \"Street\") that was required, some nodes had street names that were easily correctible but very specific.  This means they required manual checking (for example, consistency with Google Maps) and specific one-off corrections:\n",
    "\n",
    "* \"Meadowmont Village CIrcle\" becomes \"Meadowmont Village Circle\"\n",
    "* \"LaurelcherryStreet\" becomes \"Laurel Cherry Street\"\n",
    "* \"Garrett Driver\" becomes \"Garrett Drive\"\n",
    "\n",
    "Others had street names that could not be verified:\n",
    "\n",
    "* \"Triangle Family Practice\"\n",
    "*  Multiple similar names with no best choice:\n",
    "    * \"NC Highway 55 West\"\n",
    "    * \"NC Highway 55\"\n",
    "    * \"Highway West\"\n",
    "    * \"Highway 55 West\"\n",
    "    * \"Highway 55\"\n",
    "    * \"US 55\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Use of Amenity Tags for Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the data I took a look at a few of the \"education\" amenity tags ('university', 'college', and 'school') to see how the major colleges and universities in the area may be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'Duke University East Campus', 'count': 3}\n",
      "{'_id': 'Duke University Medical Center', 'count': 1}\n",
      "{'_id': 'Campbell University: Norman Adrian Wiggins School of Law', 'count': 1}\n",
      "{'_id': \"St. Augustine's University\", 'count': 1}\n",
      "{'_id': 'Duke University Central Campus', 'count': 1}\n",
      "{'_id': 'JC Raulston Arboretum at NC State University', 'count': 1}\n",
      "{'_id': 'North Carolina Central University', 'count': 1}\n",
      "{'_id': 'Duke University West Campus', 'count': 1}\n",
      "{'_id': 'North Carolina State University (Centennial Campus)', 'count': 1}\n",
      "{'_id': None, 'count': 1}\n",
      "{'_id': 'William Peace University', 'count': 1}\n",
      "{'_id': 'Campbell University RTP Campus', 'count': 1}\n"
     ]
    }
   ],
   "source": [
    "#Example Code: List of 'university' tags\n",
    "pipeline = [\n",
    "    {'$match':{'amenity':'university'}},\n",
    "    {'$group':{'_id':'$name', 'count':{'$sum':1}}},\n",
    "    {'$sort':{'count':-1}},\n",
    "]\n",
    "docs = collection.aggregate(pipeline)\n",
    "for r in docs['result']:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tags seem to be infrequently used (when a name is included) and are inconsistent when they are used.  According to the specificaitons (https://wiki.openstreetmap.org/wiki/Map_Features#Education):\n",
    "\n",
    "* \"university\" indicates a university campus.\n",
    "* \"college\" indicates a college campus or building\n",
    "* \"school\" indicates a school and grounds.\n",
    "\n",
    "While some tags are as expected (\"Duke University East Campus\" appears multiple times as \"university\"), there are issues.\n",
    "\n",
    "* There is no name for 1 universitiy, 28 college, and 21 school entries.\n",
    "* \"Durham Tech Community College\" appears as a \"college\" while \"Durham Technical Community College\" appears twice as a school.\n",
    "* \"Duke University\" is listed as a \"school\" while various campus regions are listed as \"university\".\n",
    "\n",
    "I believe that this inconsistency is at least partially to blame on the unclear documentation for these tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-standardized Postal Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most postal codes (6,564) were valid, but there were two main groups- 5-digit and 9-digit codes.  These were standardized to 5-digit codes.  Invalid codes (there were only 6) were removed.  Regular expressions were used to identify the kind of postal code and correct it as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27713\n",
      "27603\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "postcode_re = re.compile(r'^[0-9]{5}$')\n",
    "extended_postcode_re = re.compile(r'^[0-9]{5}-[0-9]{4}$')\n",
    "\n",
    "def correct_postcode(postcode):\n",
    "    \"\"\"Try to convert postcode to 5 digit int\"\"\"\n",
    "    if extended_postcode_re.match(postcode): #strip extended postcode with \"-####\"\n",
    "        postcode = postcode[0:5]\n",
    "        return int(postcode)\n",
    "    elif postcode_re.match(postcode): #normal 5 digit postcode\n",
    "        return int(postcode)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#Examples:\n",
    "print(correct_postcode('27713'))\n",
    "print(correct_postcode('27603-1407'))\n",
    "print(correct_postcode('2612-6401'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Filesizes:\n",
    "\n",
    "* XML: 486.2 MiB\n",
    "* JSON: 562.6 MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Summary info about imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,735,730 Total Records\n",
      "2,524,259 Nodes\n",
      "211,464 Ways\n"
     ]
    }
   ],
   "source": [
    "total = collection.find().count()\n",
    "total_nodes = collection.find({\"type\":\"node\"}).count()\n",
    "total_ways = collection.find({\"type\":\"way\"}).count()\n",
    "\n",
    "print(\"{:,} Total Records\".format(total))\n",
    "print(\"{:,} Nodes\".format(total_nodes))\n",
    "print(\"{:,} Ways\".format(total_ways))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Total Users and Top Users (by number of records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Users: 696\n",
      "Top Users by number of records:\n",
      "{'_id': 'jumbanho', 'count': 2139329}\n",
      "{'_id': 'woodpeck_fixbot', 'count': 128144}\n",
      "{'_id': 'yotann', 'count': 67765}\n",
      "{'_id': 'JMDeMai', 'count': 63378}\n",
      "{'_id': 'runbananas', 'count': 43244}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {'$group':{'_id':'$created.user', 'count':{'$sum':1}}},\n",
    "    {'$sort':{'count':-1}},\n",
    "]\n",
    "users = collection.aggregate(pipeline)['result']\n",
    "\n",
    "print('Total Users: {:,}'.format(len(users)))\n",
    "print('Top Users by number of records:')\n",
    "for u in users[0:5]:\n",
    "    print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changesets\n",
    "Changesets are groups of changes made by a single user over a short period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest 5 changesets:\n",
      "{'_id': {'changeset': '2453134', 'user': 'woodpeck_fixbot'}, 'count': 20133}\n",
      "{'_id': {'changeset': '3553745', 'user': 'jumbanho'}, 'count': 19980}\n",
      "{'_id': {'changeset': '3557826', 'user': 'jumbanho'}, 'count': 19861}\n",
      "{'_id': {'changeset': '3558134', 'user': 'jumbanho'}, 'count': 19860}\n",
      "{'_id': {'changeset': '3553606', 'user': 'jumbanho'}, 'count': 19849}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {'$group':{'_id':{'changeset':'$created.changeset', 'user':'$created.user'}, 'count':{'$sum':1}}},\n",
    "    {'$sort':{'count':-1}},\n",
    "    {'$limit':5}\n",
    "]\n",
    "changesets = collection.aggregate(pipeline)['result']\n",
    "\n",
    "print('Largest 5 changesets:')\n",
    "for cs in changesets:\n",
    "    print(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Type of Fuel used for BBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'charcoal', 'count': 4}\n",
      "{'_id': 'gas', 'count': 1}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {'$match':{'amenity':'bbq'}},\n",
    "    {'$group':{'_id':'$fuel', 'count':{'$sum':1}}},\n",
    "    {'$sort':{'count':-1}},\n",
    "    {'$skip':1} #'None' - no fuel tag- are listed first because they are most common.  Skip keeping them.\n",
    "]\n",
    "\n",
    "docs = collection.aggregate(pipeline)\n",
    "for r in docs['result']:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNIS and TIGER Data\n",
    "Some data was imported into OSM from GNIS (USGS Geographic Names Information System) and TIGER (Topologically Integrated Geographic Encoding and Referencing system).  This additional information may be useful for testing consistency. However, this data may be outdated and is a small fraction of the data overall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of Nodes with GNIS Data = 0.03%\n",
      "Fraction of Ways with TIGER Data = 0.65%\n"
     ]
    }
   ],
   "source": [
    "#nodes with gnis\n",
    "nodes_with = collection.find({'gnis':{'$exists':True}}).count()\n",
    "nodes_without = collection.find({'gnis':{'$exists':False}}).count()\n",
    "print(\"Fraction of Nodes with GNIS Data = {:.2%}\".format(nodes_with/(nodes_with+nodes_without)))\n",
    "\n",
    "#ways with tiger\n",
    "ways_with = collection.find({'tiger':{'$exists':True}}).count()\n",
    "ways_without = collection.find({'tiger':{'$exists':False}}).count()\n",
    "print(\"Fraction of Ways with TIGER Data = {:.2%}\".format(ways_with/(ways_with+ways_without)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232,715 total nodes (9.22%) are referenced by ways that have TIGER data.\n",
      "However, this number may include duplicate references.\n"
     ]
    }
   ],
   "source": [
    "#Number of Node references in ways with TIGER data\n",
    "pipeline = [{'$match':{'tiger':{'$exists':True}}},\n",
    "            {'$project':{'nodenum':{'$size':'$node_refs'}}},\n",
    "            {'$group':{'_id':'', 'sum':{'$sum':'$nodenum'}}}\n",
    "           ]\n",
    "docs = collection.aggregate(pipeline)\n",
    "tiger_noderefs = docs['result'][0]['sum']\n",
    "\n",
    "print('{:,} total nodes ({:.2%}) are referenced by ways that have TIGER data.'.format(\n",
    "        tiger_noderefs, tiger_noderefs/total_nodes))\n",
    "print('However, this number may include duplicate references.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in Dataset Over Time\n",
    "How has the dataset built up over time?  Using the timestamp value it is possible to count the number of nodes or ways added over time- in this case by month.  It looks like January 2010 had the highest count for both types, but big months for 'Ways' were mostly in 2013 and big months for 'Nodes' were mostly in 2009.  This is probably due to large automated imports at those times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Nodes per Month = 28,684\n",
      "Average Ways per Month = 2,458\n",
      "\n",
      "Months with the most Nodes:\n",
      " ------------------------------\n",
      "2010-01 with 1,267,448 Nodes\n",
      "2009-11 with 271,430 Nodes\n",
      "2009-07 with 144,939 Nodes\n",
      "2009-08 with 135,390 Nodes\n",
      "2009-09 with 46,642 Nodes\n",
      "\n",
      "Months with the most Ways:\n",
      " ------------------------------\n",
      "2010-01 with 89,284 Ways\n",
      "2013-02 with 20,061 Ways\n",
      "2013-01 with 7,724 Ways\n",
      "2009-11 with 7,109 Ways\n",
      "2013-04 with 5,135 Ways\n"
     ]
    }
   ],
   "source": [
    "#Group by first 7 characters of created timestamp\n",
    "from collections import Counter\n",
    "def get_monthly_count(collection, doctype):\n",
    "    \"\"\"Return the monthly count as a dict based on start of timestamp\"\"\"\n",
    "    pipeline = [\n",
    "        {'$match':{'type':doctype}},\n",
    "        {'$group':{'_id':{'$substr':['$created.timestamp',0,7]}, 'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}}\n",
    "        ]\n",
    "    counts = collection.aggregate(pipeline)['result']\n",
    "    count_dict = Counter()\n",
    "    for d in counts:\n",
    "        count_dict[d['_id']] = d['count']\n",
    "    return count_dict\n",
    "\n",
    "node_counts = get_monthly_count(collection, 'node')\n",
    "way_counts = get_monthly_count(collection, 'way')\n",
    "\n",
    "print('Average Nodes per Month = {:,}'.format(int(sum(node_counts.values())/len(node_counts))))\n",
    "print('Average Ways per Month = {:,}'.format(int(sum(way_counts.values())/len(way_counts))))\n",
    "\n",
    "print('\\nMonths with the most Nodes:\\n','-'*30)\n",
    "for m in node_counts.most_common(5):\n",
    "    print(\"{} with {:,} Nodes\".format(m[0],m[1]))\n",
    "    \n",
    "print('\\nMonths with the most Ways:\\n','-'*30)\n",
    "for m in way_counts.most_common(5):\n",
    "    print(\"{} with {:,} Ways\".format(m[0],m[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Possible Duplicate Nodes\n",
    "\n",
    "It seems that many nodes are nearly identical- they differ only in the created timestamp, id, and ObjectId.  These seem to have been imported using automated methods since the user and changeset is the same for the duplicate records and the timestamp is either the same or very close (within 5 minutes).  It may be that they were created only to serve as points in various ways or relations.\n",
    "\n",
    "These could likely be merged in order to reduce the size of the database without losing meaninful information as long as the other types of records are also checked for references to these nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,094 nodes do not have a unique position.\n"
     ]
    }
   ],
   "source": [
    "#How many nodes match at least one other node's position\n",
    "pipeline = [\n",
    "    {'$group':{'_id':'$pos', 'count':{'$sum':1}}},\n",
    "    {'$match':{'count':{'$gt':1}}}\n",
    "]\n",
    "docs = collection.aggregate(pipeline, allowDiskUse=True)['result']\n",
    "\n",
    "print(\"{:,} nodes do not have a unique position.\".format(len(docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,982 nodes do not have a unique position/changeset combo.\n"
     ]
    }
   ],
   "source": [
    "#How many match within a single changeset\n",
    "pipeline = [\n",
    "    {'$group':{'_id':{'pos':'$pos','changeset':'$created.changeset'}, 'count':{'$sum':1}}},\n",
    "    {'$match':{'count':{'$gt':1}}}\n",
    "]\n",
    "docs = collection.aggregate(pipeline, allowDiskUse=True)['result']\n",
    "\n",
    "print(\"{:,} nodes do not have a unique position/changeset combo.\".format(len(docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ \n",
      " [35.7877479, -78.8708045] \n",
      " ------------------------------ \n",
      "\n",
      "{'_id': ObjectId('559dec3e943bb0b0cde5ec4d'), 'id': '195496249', 'type': 'node', 'pos': [35.7877479, -78.8708045], 'created': {'timestamp': '2013-10-04T18:14:14Z', 'uid': '1494110', 'changeset': '18183244', 'user': 'KristenK', 'version': '7'}}\n",
      "{'_id': ObjectId('559dec6e943bb0b0cd08fd47'), 'id': '2482640856', 'type': 'node', 'pos': [35.7877479, -78.8708045], 'created': {'changeset': '18183244', 'uid': '1494110', 'user': 'KristenK', 'timestamp': '2013-10-04T18:13:55Z', 'version': '1'}}\n",
      "{'_id': ObjectId('559dec6e943bb0b0cd08fd48'), 'id': '2482640858', 'type': 'node', 'pos': [35.7877479, -78.8708045], 'created': {'changeset': '18183244', 'uid': '1494110', 'user': 'KristenK', 'timestamp': '2013-10-04T18:13:55Z', 'version': '1'}}\n",
      "{'_id': ObjectId('559dec6e943bb0b0cd08fd4a'), 'id': '2482640859', 'type': 'node', 'pos': [35.7877479, -78.8708045], 'created': {'timestamp': '2013-10-04T18:13:55Z', 'version': '1', 'changeset': '18183244', 'user': 'KristenK', 'uid': '1494110'}}\n"
     ]
    }
   ],
   "source": [
    "#Look at one set of these as an example\n",
    "pipeline = [\n",
    "    {'$group':{'_id':{'pos':'$pos','changeset':'$created.changeset'}, 'count':{'$sum':1}}},\n",
    "    {'$match':{'_id.pos':{'$exists':True}}},\n",
    "    {'$sort':{'count':-1}},\n",
    "    {'$limit':1}\n",
    "]\n",
    "docs = collection.aggregate(pipeline, allowDiskUse=True)\n",
    "\n",
    "for r in docs['result']:\n",
    "    pos = r['_id']['pos']\n",
    "    print(\"-\"*30,\"\\n\",pos,\"\\n\",\"-\"*30,\"\\n\")\n",
    "    overlaps = collection.aggregate({'$match':{'pos':pos}})\n",
    "    for o in overlaps['result']:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the data seems to be mostly valid and uniform, but there is room for improvement.  The size of the dataset could certainly be reduced by removing redundant information like duplicate nodes (same position no differing tags), but this would be a large undertaking.  The dataset shouldn't be considered anywhere near complete when it comes to annotations that aren't standard.  For example, most nodes described as a BBQ restaurant ('amenity' of 'bbq') do not list the type of fuel used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
